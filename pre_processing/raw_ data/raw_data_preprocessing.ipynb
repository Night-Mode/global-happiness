{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d2f3f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8212d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No duplicates found in Tech Data.\n",
      "\n",
      " No duplicates found in Health Data.\n",
      "\n",
      " No duplicates found in Education Data.\n",
      "\n",
      " Duplicate ISO3 codes found in Crime Data:\n",
      "    ISO3                             Country\n",
      "145  GBR  United Kingdom (England and Wales)\n",
      "146  GBR   United Kingdom (Northern Ireland)\n",
      "147  GBR           United Kingdom (Scotland)\n",
      "\n",
      "==================================================\n",
      "\n",
      " Duplicate ISO3 codes found in Income Data:\n",
      "   ISO3        Country\n",
      "40  CHN          China\n",
      "41  CHN  China (rural)\n",
      "42  CHN  China (urban)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing ISO3 mappings:\n",
      "                       Country\n",
      "28                      Kosovo\n",
      "30    Taiwan Province of China\n",
      "70                      Russia\n",
      "84   Hong Kong S.A.R. of China\n",
      "86         Congo (Brazzaville)\n",
      "93                 Ivory Coast\n",
      "95                     Turkiye\n",
      "135           Congo (Kinshasa)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "# IDI Scores\n",
    "\n",
    "# Load CSV into a Pandas DataFrame\n",
    "idi_file_path = \"IDI_Scores.csv\" \n",
    "df_tech = pd.read_csv(idi_file_path)\n",
    "\n",
    "# Rename the first column to \"Country\"\n",
    "df_tech.rename(columns={df_tech.columns[0]: \"Country\"}, inplace=True)\n",
    "df_tech.rename(columns={df_tech.columns[1]: \"Tech\"}, inplace=True)\n",
    "\n",
    "df_tech.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Health Scores\n",
    "\n",
    "# Load CSV into a Pandas DataFrame\n",
    "ghsi_file_path = \"2021-GHS-Index-April-2022.csv\"  \n",
    "df_health = pd.read_csv(ghsi_file_path)\n",
    "\n",
    "df_health = df_health[[\"Country\", \"Year\", \"OVERALL SCORE\"]]\n",
    "df_health.rename(columns={df_health.columns[2]: \"Health\"}, inplace=True)\n",
    "\n",
    "df_health = df_health[df_health[\"Year\"] == 2021]\n",
    "\n",
    "df_health = df_health[[\"Country\", \"Health\"]]\n",
    "\n",
    "df_health.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Education Scores\n",
    "\n",
    "# Load CSV into a Pandas DataFrame\n",
    "lit_file_path = \"school.csv\" \n",
    "df_edu = pd.read_csv(lit_file_path)\n",
    "\n",
    "df_edu.rename(columns={df_edu.columns[0]: \"Country\"}, inplace=True)\n",
    "df_edu.rename(columns={df_edu.columns[3]: \"Education\"}, inplace=True)\n",
    "\n",
    "# Keep only the latest year per geoUnit\n",
    "df_edu = df_edu.sort_values(by=[\"Code\", \"Year\"], ascending=[True, False]) \n",
    "df_edu = df_edu.drop_duplicates(subset=[\"Code\"], keep=\"first\")  \n",
    "\n",
    "# Rename columns for clarity\n",
    "df_edu.drop(columns=[\"Year\"], inplace=True)\n",
    "df_edu.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Violence Scores\n",
    "\n",
    "# Load the crime data CSV file\n",
    "crime_file_path = \"data_cts_violent_and_sexual_crime.csv\" \n",
    "df_crime = pd.read_csv(crime_file_path)\n",
    "\n",
    "# Filter the DataFrame to keep only the relevant categories\n",
    "df_crime_filtered = df_crime[df_crime[\"Category\"].isin([\"Serious assault\", \"Kidnapping\", \"Sexual violence\"])]\n",
    "\n",
    "# Sort by Country and Year in descending order (most recent year first)\n",
    "df_crime_filtered = df_crime_filtered.sort_values(by=[\"Country\", \"Year\"], ascending=[True, False])\n",
    "\n",
    "# Keep only the most recent year entry per Country and Category\n",
    "df_crime_filtered = df_crime_filtered.drop_duplicates(subset=[\"Country\", \"Category\"], keep=\"first\")\n",
    "\n",
    "# Group by Country and sum the values for selected categories\n",
    "df_crime_summed = df_crime_filtered.groupby(\"Country\", as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "# Rename the column to reflect the combined crime metric\n",
    "df_crime_summed.rename(columns={\"VALUE\": \"Violence\"}, inplace=True)\n",
    "\n",
    "df_crime = df_crime_summed.copy()\n",
    "df_crime.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Income Inequality\n",
    "\n",
    "# Load CSV into a Pandas DataFrame\n",
    "income_file_path = \"gini-coefficient.csv\"  \n",
    "df_income = pd.read_csv(income_file_path)\n",
    "\n",
    "df_income.rename(columns={\"Gini coefficient (before tax) (World Inequality Database)\": \"Inequality\"}, inplace=True)\n",
    "\n",
    "# Sort by Country and Year in descending order (most recent year first)\n",
    "df_income = df_income.sort_values(by=[\"Country\", \"Year\"], ascending=[True, False])\n",
    "\n",
    "# Keep only the most recent year entry per Country and Category\n",
    "df_income = df_income.drop_duplicates(subset=[\"Country\"], keep=\"first\")\n",
    "df_income = df_income[[\"Country\", \"Inequality\"]]\n",
    "\n",
    "# Drop rows where the \"Country\" column contains \"(WID)\"\n",
    "df_income = df_income[~df_income[\"Country\"].str.contains(r\"World\", na=False)]\n",
    "df_income = df_income[~df_income[\"Country\"].str.contains(r\"\\(WID\\)\", na=False)]\n",
    "\n",
    "df_income.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to convert country name to ISO3 code\n",
    "def get_iso3(country_name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(country_name).alpha_3\n",
    "    except LookupError:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "# Function to standardize location field across different dataframes\n",
    "def standardize_countries(df, country_col=\"Country\", iso3_col=\"Iso3_code\"):\n",
    "    df[\"ISO3\"] = df[country_col].apply(get_iso3)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to all five datasets\n",
    "df_tech = standardize_countries(df_tech, country_col=\"Country\", iso3_col=None)  # IDI scores\n",
    "df_health = standardize_countries(df_health, country_col=\"Country\", iso3_col=None)  # Healthcare\n",
    "df_edu = standardize_countries(df_edu, country_col=\"Country\", iso3_col=\"Code\")  # Literacy\n",
    "df_crime = standardize_countries(df_crime, country_col=\"Country\", iso3_col=None)  # Violent Crime\n",
    "df_income = standardize_countries(df_income, country_col=\"Country\", iso3_col=None)  # Poverty\n",
    "\n",
    "# Fix Missing ISOs\n",
    "manual_fixes = {\n",
    "    \"Brunei\": \"BRN\",\n",
    "    \"Cape Verde\": \"CPV\",\n",
    "    \"China (rural)\": \"CHN\",\n",
    "    \"China (urban)\": \"CHN\",\n",
    "    \"Cote d'Ivoire\": \"CIV\",\n",
    "    \"Democratic Republic of Congo\": \"COD\",\n",
    "    \"Palestine\": \"PSE\",\n",
    "    \"Russia\": \"RUS\",\n",
    "    \"Turkey\": \"TUR\",\n",
    "    \"Bolivia (Plurinational State of)\": \"BOL\",\n",
    "    \"Congo (Rep. of the)\": \"COG\",\n",
    "    \"Dem. Rep. of the Congo\": \"COD\",\n",
    "    \"Dominican Rep.\": \"\",\n",
    "    \"Hong Kong, China\": \"HKG\",\n",
    "    \"Iran (Islamic Republic of)\": \"IRN\",\n",
    "    \"Korea (Rep. of)\": \"KOR\",\n",
    "    \"Lao P.D.R.\": \"LAO\",\n",
    "    \"Macao, China\": \"MAC\",\n",
    "    \"Netherlands (Kingdom of the)\": \"NLD\",\n",
    "    \"Bosnia and Hercegovina\": \"BIH\",\n",
    "    \"Congo (Brazzaville)\": \"COG\",\n",
    "    \"Congo (Democratic Republic)\": \"COD\",\n",
    "    \"Micronesia (country)\": \"FSM\",\n",
    "    \"East Timor\": \"TLS\",\n",
    "    \"China, Hong Kong Special Administrative Region\": \"HKG\",\n",
    "    \"China, Macao Special Administrative Region\": \"MAC\",\n",
    "    \"Côte dIvoire\": \"CIV\",\n",
    "    \"Holy See\": \"VAT\",\n",
    "    \"Iraq (Central Iraq)\": \"IRQ\",\n",
    "    \"Republic of Korea\": \"KOR\",\n",
    "    \"State of Palestine\": \"PSE\",\n",
    "    \"United Kingdom (England and Wales)\": \"GBR\",\n",
    "    \"United Kingdom (Northern Ireland)\": \"GBR\",\n",
    "    \"United Kingdom (Scotland)\": \"GBR\",\n",
    "    \"Venezuela (Bolivarian Republic of)\": \"VEN\"\n",
    "}\n",
    "\n",
    "# Apply manual fixes **only where ISO3 is still missing**\n",
    "df_tech.loc[df_tech[\"ISO3\"].isna(), \"ISO3\"] = df_tech[\"Country\"].map(manual_fixes)\n",
    "df_health.loc[df_health[\"ISO3\"].isna(), \"ISO3\"] = df_health[\"Country\"].map(manual_fixes)\n",
    "df_edu.loc[df_edu[\"ISO3\"].isna(), \"ISO3\"] = df_edu[\"Country\"].map(manual_fixes)\n",
    "df_crime.loc[df_crime[\"ISO3\"].isna(), \"ISO3\"] = df_crime[\"Country\"].map(manual_fixes)\n",
    "df_income.loc[df_income[\"ISO3\"].isna(), \"ISO3\"] = df_income[\"Country\"].map(manual_fixes)\n",
    "\n",
    "# Drop rows where ISO3 is NaN for each dataframe\n",
    "df_tech = df_tech.dropna(subset=[\"ISO3\"])\n",
    "df_health = df_health.dropna(subset=[\"ISO3\"])\n",
    "df_edu = df_edu.dropna(subset=[\"ISO3\"])\n",
    "df_crime = df_crime.dropna(subset=[\"ISO3\"])\n",
    "df_income = df_income.dropna(subset=[\"ISO3\"])\n",
    "\n",
    "# Reset index after dropping rows \n",
    "df_tech.reset_index(drop=True, inplace=True)\n",
    "df_health.reset_index(drop=True, inplace=True)\n",
    "df_edu.reset_index(drop=True, inplace=True)\n",
    "df_crime.reset_index(drop=True, inplace=True)\n",
    "df_income.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to check for duplicate ISO3 values in a dataframe\n",
    "def check_duplicates(df, name):\n",
    "    duplicates = df[df.duplicated(subset=[\"ISO3\"], keep=False)]  \n",
    "    if not duplicates.empty:\n",
    "        print(f\" Duplicate ISO3 codes found in {name}:\")\n",
    "        print(duplicates[[\"ISO3\", \"Country\"]].sort_values(by=\"ISO3\")) \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    else:\n",
    "        print(f\" No duplicates found in {name}.\\n\")\n",
    "\n",
    "# Run duplicate checks on each dataframe\n",
    "check_duplicates(df_tech, \"Tech Data\")\n",
    "check_duplicates(df_health, \"Health Data\")\n",
    "check_duplicates(df_edu, \"Education Data\")\n",
    "check_duplicates(df_crime, \"Crime Data\")\n",
    "check_duplicates(df_income, \"Income Data\")\n",
    "\n",
    "# Identify and sum the Violence values for duplicate ISO3 = \"GBR\"\n",
    "gbr_sum = df_crime[df_crime[\"ISO3\"] == \"GBR\"][\"Violence\"].sum()\n",
    "\n",
    "# Create a new row for the United Kingdom with the summed value\n",
    "new_row = pd.DataFrame({\"ISO3\": [\"GBR\"], \"Country\": [\"United Kingdom\"], \"Violence\": [gbr_sum]})\n",
    "\n",
    "# Remove the individual rows for England, Scotland, and Northern Ireland\n",
    "df_crime = df_crime[df_crime[\"ISO3\"] != \"GBR\"]\n",
    "\n",
    "# Append the new aggregated row\n",
    "df_crime = pd.concat([df_crime, new_row], ignore_index=True)\n",
    "\n",
    "# Remove the rows where ISO3 is \"CHN\" and the Country is \"China (rural)\" or \"China (urban)\"\n",
    "df_income = df_income[~((df_income[\"ISO3\"] == \"CHN\") & (df_income[\"Country\"].isin([\"China (rural)\", \"China (urban)\"])))]\n",
    "\n",
    "# Drop the \"Country\" column from each dataframe before merging\n",
    "df_tech = df_tech.drop(columns=[\"Country\"], errors=\"ignore\")\n",
    "df_health = df_health.drop(columns=[\"Country\"], errors=\"ignore\")\n",
    "df_edu = df_edu.drop(columns=[\"Country\",\"Code\"], errors=\"ignore\")\n",
    "df_crime = df_crime.drop(columns=[\"Country\"], errors=\"ignore\")\n",
    "df_income = df_income.drop(columns=[\"Country\"], errors=\"ignore\")\n",
    "\n",
    "# Merge all datasets on ISO3, ensuring only complete data remains (inner join)\n",
    "df_final = df_tech.merge(df_health, on=\"ISO3\", how=\"inner\") \\\n",
    "                  .merge(df_edu, on=\"ISO3\", how=\"inner\") \\\n",
    "                  .merge(df_crime, on=\"ISO3\", how=\"inner\") \\\n",
    "                  .merge(df_income, on=\"ISO3\", how=\"inner\")\n",
    "\n",
    "# Reset index after merging\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load the scatterplot dataset\n",
    "scatterplot_file_path = \"scatterplot.csv\" \n",
    "df_scatterplot = pd.read_csv(scatterplot_file_path)\n",
    "\n",
    "# Function to convert country names to ISO3 codes\n",
    "def get_iso3(country_name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(country_name).alpha_3\n",
    "    except LookupError:\n",
    "        return None  \n",
    "\n",
    "# Add a new column \"ISO3\" and apply the mapping function\n",
    "df_scatterplot[\"ISO3\"] = df_scatterplot[\"Country\"].apply(get_iso3)\n",
    "\n",
    "# Identify rows where ISO3 is still missing (for manual resolution)\n",
    "missing_iso3 = df_scatterplot[df_scatterplot[\"ISO3\"].isna()]\n",
    "\n",
    "# Display missing mappings for manual correction\n",
    "print(\"Missing ISO3 mappings:\")\n",
    "print(missing_iso3[[\"Country\"]])\n",
    "\n",
    "manual_fixes = {\n",
    "    \"Taiwan Province of China\": \"TWN\",\n",
    "    \"Russia\": \"RUS\",\n",
    "    \"Hong Kong S.A.R. of China\": \"HKG\",\n",
    "    \"Congo (Brazzaville)\": \"COG\",\n",
    "    \"Ivory Coast\": \"CIV\",\n",
    "    \"Turkiye\": \"TUR\",\n",
    "    \"Congo (Kinshasa)\": \"COD\"\n",
    "}\n",
    "\n",
    "# Apply manual fixes where ISO3 is still missing\n",
    "df_scatterplot.loc[df_scatterplot[\"ISO3\"].isna(), \"ISO3\"] = df_scatterplot[\"Country\"].map(manual_fixes)\n",
    "\n",
    "# Identify rows where ISO3 is still missing (for manual resolution)\n",
    "missing_iso3 = df_scatterplot[df_scatterplot[\"ISO3\"].isna()]\n",
    "\n",
    "df_scatterplot = df_scatterplot.dropna(subset=[\"ISO3\"])\n",
    "df_scatterplot= df_scatterplot[[\"Ladder Score\",\"ISO3\"]]\n",
    "\n",
    "# Merge df_final with df_scatterplot on ISO3\n",
    "df_final = df_final.merge(df_scatterplot, on=\"ISO3\", how=\"inner\")\n",
    "\n",
    "# Reset index for cleanliness\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to convert ISO3 code to full country name\n",
    "def get_country_name(iso3_code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_3=iso3_code).name\n",
    "    except AttributeError:\n",
    "        return None \n",
    "\n",
    "# Create a new column \"Country_Name\" in df_final\n",
    "df_final[\"Country_Name\"] = df_final[\"ISO3\"].apply(get_country_name)\n",
    "\n",
    "# Define the desired column order\n",
    "column_order = [\"Country_Name\", \"ISO3\", \"Ladder Score\", \"Tech\", \"Health\", \"Education\", \"Violence\", \"Inequality\"]\n",
    "\n",
    "# Reorder the dataframe columns\n",
    "df_final = df_final[column_order]\n",
    "\n",
    "# Define the columns to classify\n",
    "columns_to_classify = [\"Tech\", \"Health\", \"Education\", \"Violence\", \"Inequality\"]\n",
    "\n",
    "# Function to assign levels (1-5) based on quantiles\n",
    "def assign_levels(series):\n",
    "    return pd.qcut(series, q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Apply classification to each column\n",
    "for col in columns_to_classify:\n",
    "    df_final[col + \"_Level\"] = assign_levels(df_final[col])\n",
    "\n",
    "# Load a mapping of ISO3 codes to regions\n",
    "region_df = pd.read_csv('https://raw.githubusercontent.com/datasets/country-codes/master/data/country-codes.csv')\n",
    "\n",
    "# Keep only the necessary columns\n",
    "region_df = region_df[['ISO3166-1-Alpha-3', 'Region Name']]\n",
    "region_df.columns = ['ISO3', 'region']\n",
    "\n",
    "# Merge the region info\n",
    "df = df_final.merge(region_df, on='ISO3', how='left')\n",
    "\n",
    "# Custom ISO3 to subregion mapping\n",
    "iso3_to_subregion = {\n",
    "    # Americas\n",
    "    \"USA\": \"North America\", \"CAN\": \"North America\", \"MEX\": \"North America\",\n",
    "    \"BLZ\": \"Central America\", \"GTM\": \"Central America\", \"HND\": \"Central America\", \n",
    "    \"SLV\": \"Central America\", \"NIC\": \"Central America\", \"CRI\": \"Central America\", \n",
    "    \"PAN\": \"Central America\",\n",
    "    \"ARG\": \"South America\", \"BOL\": \"South America\", \"BRA\": \"South America\", \n",
    "    \"CHL\": \"South America\", \"COL\": \"South America\", \"ECU\": \"South America\", \n",
    "    \"GUY\": \"South America\", \"PRY\": \"South America\", \"PER\": \"South America\", \n",
    "    \"SUR\": \"South America\", \"URY\": \"South America\", \"VEN\": \"South America\",\n",
    "    \"JAM\": \"North America\", \n",
    "    \n",
    "    # Africa\n",
    "    \"DZA\": \"North Africa\", \"EGY\": \"North Africa\", \"LBY\": \"North Africa\", \n",
    "    \"MAR\": \"North Africa\", \"SDN\": \"North Africa\", \"TUN\": \"North Africa\",\n",
    "    \"AGO\": \"Central Africa\", \"CMR\": \"Central Africa\", \"CAF\": \"Central Africa\", \n",
    "    \"COD\": \"Central Africa\", \"COG\": \"Central Africa\", \"GNQ\": \"Central Africa\", \n",
    "    \"GAB\": \"Central Africa\", \"STP\": \"Central Africa\",\n",
    "    \"ZAF\": \"Southern Africa\", \"NAM\": \"Southern Africa\", \"BWA\": \"Southern Africa\", \n",
    "    \"LSO\": \"Southern Africa\", \"SWZ\": \"Southern Africa\", \"ZMB\": \"Southern Africa\", \n",
    "    \"MWI\": \"Southern Africa\", \"MOZ\": \"Southern Africa\", \"ZWE\": \"Southern Africa\",\n",
    "    \"NER\": \"West Africa\", \"NGA\": \"West Africa\", \"SEN\": \"West Africa\", \n",
    "    \"MLI\": \"West Africa\", \"GHA\": \"West Africa\", \"CIV\": \"West Africa\", \n",
    "    \"BFA\": \"West Africa\", \"GIN\": \"West Africa\", \"TGO\": \"West Africa\", \n",
    "    \"BEN\": \"West Africa\", \"SLE\": \"West Africa\", \"LBR\": \"West Africa\", \n",
    "    \"GMB\": \"West Africa\", \"CPV\": \"West Africa\", \"KEN\": \"Central Africa\",\n",
    "    \"MDG\": \"Southern Africa\", \"MUS\": \"Southern Africa\", \"TZA\": \"Central Africa\",\n",
    "    \"UGA\": \"Central Africa\",\n",
    "\n",
    "    # Europe\n",
    "    \"ALB\": \"Southern Europe\", \"AND\": \"Southern Europe\", \"BIH\": \"Southern Europe\",\n",
    "    \"HRV\": \"Southern Europe\", \"GRC\": \"Southern Europe\", \"ITA\": \"Southern Europe\", \n",
    "    \"MLT\": \"Southern Europe\", \"MNE\": \"Southern Europe\", \"MKD\": \"Southern Europe\", \n",
    "    \"PRT\": \"Southern Europe\", \"SMR\": \"Southern Europe\", \"SRB\": \"Southern Europe\", \n",
    "    \"SVN\": \"Southern Europe\", \"ESP\": \"Southern Europe\",\n",
    "    \"AUT\": \"Western Europe\", \"BEL\": \"Western Europe\", \"FRA\": \"Western Europe\", \n",
    "    \"DEU\": \"Western Europe\", \"LUX\": \"Western Europe\", \"MCO\": \"Western Europe\", \n",
    "    \"NLD\": \"Western Europe\", \"CHE\": \"Western Europe\",\n",
    "    \"CYP\": \"Eastern Europe\", \"CZE\": \"Eastern Europe\", \"EST\": \"Eastern Europe\", \n",
    "    \"HUN\": \"Eastern Europe\", \"LVA\": \"Eastern Europe\", \"LTU\": \"Eastern Europe\", \n",
    "    \"POL\": \"Eastern Europe\", \"SVK\": \"Eastern Europe\", \"UKR\": \"Eastern Europe\", \n",
    "    \"ROU\": \"Eastern Europe\", \"BGR\": \"Eastern Europe\", \"RUS\": \"Eastern Europe\", \n",
    "    \"MDA\": \"Eastern Europe\", \"ARM\": \"Eastern Europe\", \"GEO\": \"Eastern Europe\",\n",
    "    \"DNK\": \"Northern Europe\", \"FIN\": \"Northern Europe\", \"ISL\": \"Northern Europe\", \n",
    "    \"IRL\": \"Northern Europe\", \"NOR\": \"Northern Europe\", \"SWE\": \"Northern Europe\", \n",
    "    \"GBR\": \"Northern Europe\",\n",
    "\n",
    "    # Asia\n",
    "    \"CHN\": \"East Asia\", \"JPN\": \"East Asia\", \"KOR\": \"East Asia\", \"MNG\": \"East Asia\", \n",
    "    \"TWN\": \"East Asia\", \"HKG\": \"East Asia\",\n",
    "    \"IND\": \"South Asia\", \"PAK\": \"South Asia\", \"BGD\": \"South Asia\", \"LKA\": \"South Asia\", \n",
    "    \"NPL\": \"South Asia\", \"BTN\": \"South Asia\", \"MDV\": \"South Asia\",\n",
    "    \"THA\": \"Southeast Asia\", \"VNM\": \"Southeast Asia\", \"IDN\": \"Southeast Asia\", \n",
    "    \"PHL\": \"Southeast Asia\", \"MYS\": \"Southeast Asia\", \"SGP\": \"Southeast Asia\", \n",
    "    \"MMR\": \"Southeast Asia\", \"KHM\": \"Southeast Asia\", \"LAO\": \"Southeast Asia\", \n",
    "    \"BRN\": \"Southeast Asia\", \"TLS\": \"Southeast Asia\",\n",
    "    \"KAZ\": \"Central Asia\", \"UZB\": \"Central Asia\", \"TKM\": \"Central Asia\", \n",
    "    \"KGZ\": \"Central Asia\", \"TJK\": \"Central Asia\",\n",
    "    \"TUR\": \"Middle East\", \"IRN\": \"Middle East\", \"IRQ\": \"Middle East\", \"ISR\": \"Middle East\", \n",
    "    \"SAU\": \"Middle East\", \"JOR\": \"Middle East\", \"SYR\": \"Middle East\", \"LBN\": \"Middle East\", \n",
    "    \"OMN\": \"Middle East\", \"QAT\": \"Middle East\", \"ARE\": \"Middle East\", \"KWT\": \"Middle East\", \n",
    "    \"BHR\": \"Middle East\", \"YEM\": \"Middle East\", \"AZE\": \"Middle East\",\n",
    "\n",
    "    # Oceania\n",
    "    \"AUS\": \"Oceania\", \"NZL\": \"Oceania\", \n",
    "    \"FJI\": \"Oceania\", \"PNG\": \"Oceania\", \"SLB\": \"Oceania\", \n",
    "    \"WSM\": \"Oceania\", \"TON\": \"Oceania\", \"VUT\": \"Oceania\"\n",
    "}\n",
    "\n",
    "# Add subregion column using the mapping\n",
    "df['subregion'] = df['ISO3'].map(iso3_to_subregion)\n",
    "\n",
    "# Output to CSV\n",
    "output_file_path = \"final_merged_regions.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c11174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "scatter_df = pd.read_csv(\"scatterplot.csv\")\n",
    "regions_df = pd.read_csv(\"final_merged_regions.csv\")\n",
    "\n",
    "# Standardize country names for better merging\n",
    "country_name_mapping = {\n",
    "    \"Korea, Republic of\": \"South Korea\",\n",
    "    \"Moldova, Republic of\": \"Moldova\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Tanzania, United Republic of\": \"Tanzania\",\n",
    "    \"Türkiye\": \"Turkiye\"\n",
    "}\n",
    "regions_df[\"Country_Name\"] = regions_df[\"Country_Name\"].replace(country_name_mapping)\n",
    "\n",
    "# Merge datasets on country name\n",
    "merged_df = regions_df.merge(\n",
    "    scatter_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"Country_Name\",\n",
    "    right_on=\"Country\"\n",
    ")\n",
    "\n",
    "# Drop redundant 'Country' column from scatter_df\n",
    "merged_df.drop(columns=[\"Country\"], inplace=True)\n",
    "\n",
    "# Fix Ladder Score column from scatter_df\n",
    "merged_df.drop(columns=[\"Ladder Score_x\"], inplace=True)\n",
    "merged_df.rename(columns={\"Ladder Score_y\": \"Ladder Score\"}, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "happiness_columns = [\n",
    "    'Ladder Score', 'Log GDP per capita', 'Social Support',\n",
    "    'Healthy Life Expectancy', 'Personal Freedom', 'Generosity',\n",
    "    'Perceptions of Corruption', 'Dystopia'\n",
    "]\n",
    "\n",
    "additional_columns = [\n",
    "    'Tech', 'Health', 'Education', 'Violence', 'Inequality'\n",
    "]\n",
    "\n",
    "ordered_columns = (\n",
    "    ['Country_Name', 'ISO3', 'region', 'subregion'] +\n",
    "    happiness_columns + additional_columns +\n",
    "    [col for col in merged_df.columns if col not in happiness_columns + additional_columns + ['Country_Name', 'ISO3', 'region', 'subregion']]\n",
    ")\n",
    "\n",
    "merged_df = merged_df[ordered_columns]\n",
    "\n",
    "# Save the final dataset\n",
    "merged_df.to_csv(\"merged_boxplot_data_cleaned.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
